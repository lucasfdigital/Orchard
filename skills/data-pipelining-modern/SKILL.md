---
name: data-pipelining-modern
description: Engenharia de Dados Moderna. Diretrizes de alto desempenho para pipelines usando Polars, DuckDB, Apache Arrow e dbt. Use para ETL/ELT, modelagem dimensional e processamento de grandes volumes de dados.
allowed-tools: Read, Write, Edit, Bash
version: 1.0
priority: HIGH
---

# Data Pipelining Moderno - Alta Performance e Escalabilidade

> **SKILL DE DADOS** - Transforme dados em inteligÃªncia com **velocidade, precisÃ£o e baixo custo**.

---

## PrincÃ­pios de Dados Orchard

| PrincÃ­pio | Regra |
| :--- | :--- |
| **IdempotÃªncia** | Pipelines devem poder ser reexecutados sem duplicidade. |
| **Modelagem OBT** | One Big Table para performance em BI. |
| **Data Contracts** | Schemas definidos e validados entre Produtor e Consumidor. |
| **Colunar > Linha** | Parquet, Arrow e Polars para eficiÃªncia de leitura. |

---

## Stack TecnolÃ³gica Recomendada

| Ferramenta | Por que usar no Orchard? |
| :--- | :--- |
| **Polars** | Melhores benchmarks in-memory. Substitua o Pandas. |
| **DuckDB** | O "SQLite dos dados". Ideal para OLAP local e transformaÃ§Ãµes leves. |
| **Apache Arrow** | Formato universal para zero-copy data exchange. |
| **dbt** | MÃ³dulos SQL, versionamento e documentaÃ§Ã£o em um sÃ³ lugar. |

---

## PadrÃµes de Arquitetura (Medallion)

| Camada | MissÃ£o |
| :--- | :--- |
| **Bronze (Raw)** | Carregamento bruto da origem. Preserve o histÃ³rico. |
| **Silver (Cleaned)** | DesduplicaÃ§Ã£o, normalizaÃ§Ã£o e tratamento de nulos. |
| **Gold (Business)** | AgregaÃ§Ãµes, KPIs e visÃµes de negÃ³cio (Data Marts). |

---

## Melhores PrÃ¡ticas de Performance

| CenÃ¡rio | EstratÃ©gia Recomendada |
| :--- | :--- |
| **Processamento Local** | Use Polars `.lazy()` para otimizaÃ§Ã£o automÃ¡tica de queries. |
| **Dados que Excedem RAM** | Use DuckDB com leitura direta de arquivos Parquet em disco. |
| **Incremental Loading** | Carregue apenas os novos registros (`timestamp` da Ãºltima carga). |
| **Partitioning** | Particione por Data/Ano no S3/GCS para queries rÃ¡pidas. |

---

## Qualidade e GovernanÃ§a de Dados

| AÃ§Ã£o | Ferramenta/PadrÃ£o |
| :--- | :--- |
| **Testes de Schema** | Use `pydantic` ou `pandera` para validar tipos e ranges. |
| **Data Lineage** | Mantenha o grÃ¡fico de dependÃªncia visual do dbt sempre atualizado. |
| **DocumentaÃ§Ã£o AI-ready** | Descreva cada coluna no YAML para que a IA possa analisar os dados. |
| **Anonymization** | Mascare PII (RG, CPF, Email) conforme a LGPD. |

---

## Anti-PadrÃµes de Dados (NÃƒO FAÃ‡A)

| âŒ PadrÃ£o | âœ… CorreÃ§Ã£o |
| :--- | :--- |
| Processar tudo em Loop For | Use operaÃ§Ãµes vetorizadas (Pandas/Polars). |
| Chamar API dentro do Loop | FaÃ§a chamadas em batch (em massa). |
| Usar CSV para Big Data | Use Parquet ou Avro para compressÃ£o e performance. |
| Senha hardcoded no script | Use variÃ¡veis de ambiente (.env). |

---

## ğŸ—ï¸ Exemplo de Pipeline Polars (In-Memory)

```python
import polars as pl

def process_gold_layer():
    # Lazy evaluation = performance mÃ¡xima
    df = pl.scan_parquet("silver/orders.parquet") \
        .filter(pl.col("status") == "delivered") \
        .group_by("customer_id") \
        .agg(pl.sum("total_amount").alias("lifetime_value")) \
        .collect() # Executa a query otimizada
    
    df.write_parquet("gold/customer_ltv.parquet")
```

---

> ğŸ”´ **"Se o seu pipeline de dados demora mais que 30s para processar 1M de linhas, vocÃª precisa otimizar."**

*Transformando dados em valor no projeto Orchard. LicenÃ§a MIT.*
